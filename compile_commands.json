[
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/bin/cc -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem /usr/local/cuda/include -g -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -fopenmp -std=gnu11 -o CMakeFiles/ggml.dir/ggml.c.o -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml.c",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml.c"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/bin/cc -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem /usr/local/cuda/include -g -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -fopenmp -std=gnu11 -o CMakeFiles/ggml.dir/ggml-alloc.c.o -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-alloc.c",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-alloc.c"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/bin/c++ -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem /usr/local/cuda/include -g -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -fopenmp -std=gnu++11 -o CMakeFiles/ggml.dir/ggml-backend.cpp.o -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-backend.cpp",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-backend.cpp"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/bin/cc -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem /usr/local/cuda/include -g -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -fopenmp -std=gnu11 -o CMakeFiles/ggml.dir/ggml-quants.c.o -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-quants.c",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-quants.c"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/acc.cu -o CMakeFiles/ggml.dir/ggml-cuda/acc.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/acc.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/arange.cu -o CMakeFiles/ggml.dir/ggml-cuda/arange.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/arange.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/argmax.cu -o CMakeFiles/ggml.dir/ggml-cuda/argmax.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/argmax.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/argsort.cu -o CMakeFiles/ggml.dir/ggml-cuda/argsort.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/argsort.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/binbcast.cu -o CMakeFiles/ggml.dir/ggml-cuda/binbcast.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/binbcast.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/clamp.cu -o CMakeFiles/ggml.dir/ggml-cuda/clamp.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/clamp.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/concat.cu -o CMakeFiles/ggml.dir/ggml-cuda/concat.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/concat.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/conv-transpose-1d.cu -o CMakeFiles/ggml.dir/ggml-cuda/conv-transpose-1d.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/conv-transpose-1d.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/convert.cu -o CMakeFiles/ggml.dir/ggml-cuda/convert.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/convert.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/count-equal.cu -o CMakeFiles/ggml.dir/ggml-cuda/count-equal.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/count-equal.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/cpy.cu -o CMakeFiles/ggml.dir/ggml-cuda/cpy.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/cpy.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/cross-entropy-loss.cu -o CMakeFiles/ggml.dir/ggml-cuda/cross-entropy-loss.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/cross-entropy-loss.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/diagmask.cu -o CMakeFiles/ggml.dir/ggml-cuda/diagmask.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/diagmask.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/dmmv.cu -o CMakeFiles/ggml.dir/ggml-cuda/dmmv.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/dmmv.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/fattn-tile-f16.cu -o CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f16.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/fattn-tile-f16.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/fattn-tile-f32.cu -o CMakeFiles/ggml.dir/ggml-cuda/fattn-tile-f32.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/fattn-tile-f32.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/fattn.cu -o CMakeFiles/ggml.dir/ggml-cuda/fattn.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/fattn.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/getrows.cu -o CMakeFiles/ggml.dir/ggml-cuda/getrows.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/getrows.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/im2col.cu -o CMakeFiles/ggml.dir/ggml-cuda/im2col.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/im2col.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/mmq.cu -o CMakeFiles/ggml.dir/ggml-cuda/mmq.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/mmq.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/mmvq.cu -o CMakeFiles/ggml.dir/ggml-cuda/mmvq.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/mmvq.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/norm.cu -o CMakeFiles/ggml.dir/ggml-cuda/norm.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/norm.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/opt-step-adamw.cu -o CMakeFiles/ggml.dir/ggml-cuda/opt-step-adamw.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/opt-step-adamw.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/out-prod.cu -o CMakeFiles/ggml.dir/ggml-cuda/out-prod.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/out-prod.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/pad.cu -o CMakeFiles/ggml.dir/ggml-cuda/pad.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/pad.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/pool2d.cu -o CMakeFiles/ggml.dir/ggml-cuda/pool2d.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/pool2d.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/quantize.cu -o CMakeFiles/ggml.dir/ggml-cuda/quantize.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/quantize.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/rope.cu -o CMakeFiles/ggml.dir/ggml-cuda/rope.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/rope.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/rwkv-wkv.cu -o CMakeFiles/ggml.dir/ggml-cuda/rwkv-wkv.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/rwkv-wkv.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/scale.cu -o CMakeFiles/ggml.dir/ggml-cuda/scale.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/scale.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/softmax.cu -o CMakeFiles/ggml.dir/ggml-cuda/softmax.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/softmax.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/sum.cu -o CMakeFiles/ggml.dir/ggml-cuda/sum.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/sum.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/sumrows.cu -o CMakeFiles/ggml.dir/ggml-cuda/sumrows.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/sumrows.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/tsembd.cu -o CMakeFiles/ggml.dir/ggml-cuda/tsembd.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/tsembd.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/unary.cu -o CMakeFiles/ggml.dir/ggml-cuda/unary.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/unary.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/upscale.cu -o CMakeFiles/ggml.dir/ggml-cuda/upscale.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/upscale.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda.cu -o CMakeFiles/ggml.dir/ggml-cuda.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb16.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqfloat-cpb32.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb16.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb32.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-wmma-f16-instance-kqhalf-cpb8.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-iq1_s.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq1_s.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-iq2_s.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_s.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-iq2_xs.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xs.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-iq2_xxs.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq2_xxs.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-iq3_s.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_s.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-iq3_xxs.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq3_xxs.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-iq4_nl.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_nl.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-iq4_xs.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-iq4_xs.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-q2_k.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q2_k.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-q3_k.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q3_k.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-q4_0.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_0.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-q4_1.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_1.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-q4_k.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q4_k.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-q5_0.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_0.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-q5_1.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_1.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-q5_k.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q5_k.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-q6_k.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q6_k.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/mmq-instance-q8_0.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/mmq-instance-q8_0.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q4_0-q4_0.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q4_0-q4_0.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-q8_0-q8_0.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-q8_0-q8_0.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs128-f16-f16.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs256-f16-f16.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f16-instance-hs64-f16-f16.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs128-f16-f16.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs256-f16-f16.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/local/cuda/bin/nvcc -forward-unknown-to-host-compiler -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem=/usr/local/cuda/include -g --generate-code=arch=compute_52,code=[compute_52,sm_52] --generate-code=arch=compute_61,code=[compute_61,sm_61] --generate-code=arch=compute_70,code=[compute_70,sm_70] --generate-code=arch=compute_75,code=[compute_75,sm_75] -Xcompiler=-fPIC -use_fast_math -Xcompiler \"-Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic -march=native\" -std=c++11 -x cu -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu -o CMakeFiles/ggml.dir/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu.o",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-cuda/template-instances/fattn-vec-f32-instance-hs64-f16-f16.cu"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src",
  "command": "/usr/bin/cc -DGGML_BUILD -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 -DGGML_SCHED_MAX_COPIES=4 -DGGML_SHARED -DGGML_USE_CUDA -DGGML_USE_OPENMP -DK_QUANTS_PER_ITERATION=2 -D_GLIBCXX_ASSERTIONS -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dggml_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/. -isystem /usr/local/cuda/include -g -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -fopenmp -std=gnu11 -o CMakeFiles/ggml.dir/ggml-aarch64.c.o -c /mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-aarch64.c",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/ggml/src/ggml-aarch64.c"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/src",
  "command": "/usr/bin/c++ -DGGML_USE_CUDA -DWHISPER_BUILD -DWHISPER_SHARED -Dwhisper_EXPORTS -I/mnt/d/ai/whisper.cpp.qwen2/src/. -I/mnt/d/ai/whisper.cpp.qwen2/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -g -fPIC -o CMakeFiles/whisper.dir/qwen2-whisper.cpp.o -c /mnt/d/ai/whisper.cpp.qwen2/src/qwen2-whisper.cpp",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/src/qwen2-whisper.cpp"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/examples",
  "command": "/usr/bin/c++ -DGGML_USE_CUDA -I/mnt/d/ai/whisper.cpp.qwen2/examples -I/mnt/d/ai/whisper.cpp.qwen2/src/. -I/mnt/d/ai/whisper.cpp.qwen2/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -g -fPIC -o CMakeFiles/common.dir/common.cpp.o -c /mnt/d/ai/whisper.cpp.qwen2/examples/common.cpp",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/examples/common.cpp"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/examples",
  "command": "/usr/bin/c++ -DGGML_USE_CUDA -I/mnt/d/ai/whisper.cpp.qwen2/examples -I/mnt/d/ai/whisper.cpp.qwen2/src/. -I/mnt/d/ai/whisper.cpp.qwen2/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -g -fPIC -o CMakeFiles/common.dir/common-ggml.cpp.o -c /mnt/d/ai/whisper.cpp.qwen2/examples/common-ggml.cpp",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/examples/common-ggml.cpp"
},
{
  "directory": "/mnt/d/ai/whisper.cpp.qwen2/examples/main",
  "command": "/usr/bin/c++ -DGGML_USE_CUDA -I/mnt/d/ai/whisper.cpp.qwen2/examples -I/mnt/d/ai/whisper.cpp.qwen2/src/. -I/mnt/d/ai/whisper.cpp.qwen2/src/../include -I/mnt/d/ai/whisper.cpp.qwen2/ggml/src/../include -g -o CMakeFiles/main.dir/main.cpp.o -c /mnt/d/ai/whisper.cpp.qwen2/examples/main/main.cpp",
  "file": "/mnt/d/ai/whisper.cpp.qwen2/examples/main/main.cpp"
}
]